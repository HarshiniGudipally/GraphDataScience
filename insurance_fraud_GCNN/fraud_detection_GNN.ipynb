{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Packages\n",
    "\n",
    "    Requirements for the fraud detection project using Graph Neural Networks, here's the command to install all the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install torch_geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud detection using GNN on synthetic transactions data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    This end-to-end implementation demonstrates how to use Graph Neural Networks for fraud detection in financial transactions. The GNN model can capture complex relationships in the data, potentially leading to improved fraud detection compared to traditional machine learning approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "    Data Loading and Preprocessing\n",
    "\n",
    "    In this step, we load the synthetic transaction and identity datasets, merge them based on TransactionID, encode categorical variables, normalize numerical features, and split the data into training and test sets. This preprocessing is crucial for preparing the data for the GNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TransactionID  ProductCD  TransactionAmt       card_no  card_type  isFraud  \\\n",
      "0              1          2        0.680281  3863XXXX2177          2        0   \n",
      "1              2          3        0.124621  5760XXXX1011          1        0   \n",
      "2              3          0       -0.652243  6252XXXX5399          1        0   \n",
      "3              4          2        1.076765  9234XXXX6445          1        0   \n",
      "4              5          2        0.634218  7570XXXX9212          0        0   \n",
      "\n",
      "   email_domain        IpAddress       PhoneNo  DeviceID  \n",
      "0             1  246.191.145.201  593-800-9182       125  \n",
      "1             2  161.245.212.205  819-213-5117       173  \n",
      "2             0  220.240.157.141  448-825-5778       300  \n",
      "3             1    46.35.253.134  934-665-3953       910  \n",
      "4             1    82.115.197.47  909-419-1276       532  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "# Load the synthetic datasets\n",
    "transactions_df = pd.read_csv('synthetic_transactions.csv')\n",
    "identity_df = pd.read_csv('synthetic_identity.csv')\n",
    "\n",
    "# Merge the datasets on TransactionID\n",
    "merged_df = pd.merge(transactions_df, identity_df, on='TransactionID')\n",
    "\n",
    "# Encode categorical variables\n",
    "encoder = LabelEncoder()\n",
    "categorical_cols = ['ProductCD', 'card_type', 'email_domain', 'DeviceID']\n",
    "for col in categorical_cols:\n",
    "    merged_df[col] = encoder.fit_transform(merged_df[col])\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "merged_df['TransactionAmt'] = scaler.fit_transform(merged_df[['TransactionAmt']])\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_df, test_df = train_test_split(merged_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 \n",
    "    Graph Construction\n",
    "\n",
    "    This step constructs a heterogeneous graph from the preprocessed data. We create nodes for transactions, cards, emails, IP addresses, and devices, and establish edges between them. The graph structure allows the GNN to capture complex relationships between different entities in the transaction data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(df):\n",
    "    data = HeteroData()\n",
    "    \n",
    "    # Add node features\n",
    "    data['transaction'].x = torch.tensor(df[['ProductCD', 'TransactionAmt']].values, dtype=torch.float)\n",
    "    data['card'].x = torch.tensor(df['card_type'].values.reshape(-1, 1), dtype=torch.float)\n",
    "    data['email'].x = torch.tensor(df['email_domain'].values.reshape(-1, 1), dtype=torch.float)\n",
    "    data['ip'].x = torch.tensor(df['IpAddress'].astype('category').cat.codes.values.reshape(-1, 1), dtype=torch.float)\n",
    "    data['device'].x = torch.tensor(df['DeviceID'].values.reshape(-1, 1), dtype=torch.float)\n",
    "    \n",
    "    # Add edges\n",
    "    num_nodes = len(df)\n",
    "    data['transaction', 'uses', 'card'].edge_index = torch.tensor(np.array([range(num_nodes), range(num_nodes)]), dtype=torch.long)\n",
    "    data['transaction', 'from', 'email'].edge_index = torch.tensor(np.array([range(num_nodes), range(num_nodes)]), dtype=torch.long)\n",
    "    data['transaction', 'through', 'ip'].edge_index = torch.tensor(np.array([range(num_nodes), range(num_nodes)]), dtype=torch.long)\n",
    "    data['transaction', 'via', 'device'].edge_index = torch.tensor(np.array([range(num_nodes), range(num_nodes)]), dtype=torch.long)\n",
    "    \n",
    "    # Add reverse edges\n",
    "    data['card', 'rev_uses', 'transaction'].edge_index = data['transaction', 'uses', 'card'].edge_index.flip(0)\n",
    "    data['email', 'rev_from', 'transaction'].edge_index = data['transaction', 'from', 'email'].edge_index.flip(0)\n",
    "    data['ip', 'rev_through', 'transaction'].edge_index = data['transaction', 'through', 'ip'].edge_index.flip(0)\n",
    "    data['device', 'rev_via', 'transaction'].edge_index = data['transaction', 'via', 'device'].edge_index.flip(0)\n",
    "    \n",
    "    # Add target\n",
    "    data['transaction'].y = torch.tensor(df['isFraud'].values, dtype=torch.long)\n",
    "    \n",
    "    return data\n",
    "\n",
    "train_data = create_graph(train_df)\n",
    "test_data = create_graph(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "    Define the GNN Model\n",
    "\n",
    "    Here, we define the Graph Neural Network model using PyTorch Geometric. The model uses HeteroConv layers with SAGEConv operations to process the heterogeneous graph data. The model architecture includes two graph convolution layers with ReLU activation in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN(\n",
      "  (encoder): GNNEncoder(\n",
      "    (conv1): HeteroConv(num_relations=8)\n",
      "    (conv2): HeteroConv(num_relations=8)\n",
      "  )\n",
      "  (lin): Linear(32, 1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv, HeteroConv, Linear\n",
    "from torch_geometric.nn import to_hetero\n",
    "\n",
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('transaction', 'uses', 'card'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('transaction', 'from', 'email'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('transaction', 'through', 'ip'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('transaction', 'via', 'device'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('card', 'rev_uses', 'transaction'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('email', 'rev_from', 'transaction'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('ip', 'rev_through', 'transaction'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('device', 'rev_via', 'transaction'): SAGEConv((-1, -1), hidden_channels),\n",
    "        })\n",
    "        self.conv2 = HeteroConv({\n",
    "            ('transaction', 'uses', 'card'): SAGEConv((-1, -1), out_channels),\n",
    "            ('transaction', 'from', 'email'): SAGEConv((-1, -1), out_channels),\n",
    "            ('transaction', 'through', 'ip'): SAGEConv((-1, -1), out_channels),\n",
    "            ('transaction', 'via', 'device'): SAGEConv((-1, -1), out_channels),\n",
    "            ('card', 'rev_uses', 'transaction'): SAGEConv((-1, -1), out_channels),\n",
    "            ('email', 'rev_from', 'transaction'): SAGEConv((-1, -1), out_channels),\n",
    "            ('ip', 'rev_through', 'transaction'): SAGEConv((-1, -1), out_channels),\n",
    "            ('device', 'rev_via', 'transaction'): SAGEConv((-1, -1), out_channels),\n",
    "        })\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict = {key: x.relu() for key, x in x_dict.items()}\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "        return x_dict\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(hidden_channels, out_channels)\n",
    "        self.lin = Linear(out_channels, 1)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        return self.lin(z_dict['transaction']).view(-1)\n",
    "\n",
    "# Create the model\n",
    "model = GNN(hidden_channels=64, out_channels=32)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4\n",
    "    Training the Model\n",
    "\n",
    "    This step defines the training process for the GNN model. We use Adam optimizer and CrossEntropyLoss as the loss function. The training loop runs for 200 epochs, updating the model parameters to minimize the loss on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Loss: 42.6504\n",
      "Epoch: 020, Loss: 38.6691\n",
      "Epoch: 030, Loss: 9.7998\n",
      "Epoch: 040, Loss: 33.6104\n",
      "Epoch: 050, Loss: 47.6280\n",
      "Epoch: 060, Loss: 44.1196\n",
      "Epoch: 070, Loss: 35.5335\n",
      "Epoch: 080, Loss: 26.8551\n",
      "Epoch: 090, Loss: 19.4989\n",
      "Epoch: 100, Loss: 13.5614\n",
      "Epoch: 110, Loss: 8.6513\n",
      "Epoch: 120, Loss: 4.4195\n",
      "Epoch: 130, Loss: 0.5431\n",
      "Epoch: 140, Loss: 2.5694\n",
      "Epoch: 150, Loss: 1.2637\n",
      "Epoch: 160, Loss: 0.3345\n",
      "Epoch: 170, Loss: 0.2360\n",
      "Epoch: 180, Loss: 1.1230\n",
      "Epoch: 190, Loss: 0.3712\n",
      "Epoch: 200, Loss: 6.7911\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "train_data = train_data.to(device)\n",
    "test_data = test_data.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(train_data.x_dict, train_data.edge_index_dict)\n",
    "    loss = criterion(out, train_data['transaction'].y.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'fraud_detection_model.pth')\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 \n",
    "    Evaluation\n",
    "\n",
    "    In the final step, we evaluate the trained model on both the training and test datasets. The test function computes the accuracy of the model's predictions. We report the accuracy on both the training and test sets to assess the model's performance and check for potential overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9888\n",
      "Test Accuracy: 0.9900\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    pred = out.sigmoid().round()\n",
    "    correct = (pred == data['transaction'].y).sum()\n",
    "    acc = int(correct) / int(data['transaction'].y.shape[0])\n",
    "    return acc\n",
    "\n",
    "train_acc = test(train_data)\n",
    "test_acc = test(test_data)\n",
    "print(f'Train Accuracy: {train_acc:.4f}')\n",
    "print(f'Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_79188\\3816368336.py:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('fraud_detection_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the transaction details:\n",
      "Fraud probability for the transaction: 0.0215\n",
      "This transaction appears to be legitimate.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch_geometric.data import HeteroData\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load the trained model\n",
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('transaction', 'uses', 'card'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('transaction', 'from', 'email'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('transaction', 'through', 'ip'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('transaction', 'via', 'device'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('card', 'rev_uses', 'transaction'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('email', 'rev_from', 'transaction'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('ip', 'rev_through', 'transaction'): SAGEConv((-1, -1), hidden_channels),\n",
    "            ('device', 'rev_via', 'transaction'): SAGEConv((-1, -1), hidden_channels),\n",
    "        })\n",
    "        self.conv2 = HeteroConv({\n",
    "            ('transaction', 'uses', 'card'): SAGEConv((-1, -1), out_channels),\n",
    "            ('transaction', 'from', 'email'): SAGEConv((-1, -1), out_channels),\n",
    "            ('transaction', 'through', 'ip'): SAGEConv((-1, -1), out_channels),\n",
    "            ('transaction', 'via', 'device'): SAGEConv((-1, -1), out_channels),\n",
    "            ('card', 'rev_uses', 'transaction'): SAGEConv((-1, -1), out_channels),\n",
    "            ('email', 'rev_from', 'transaction'): SAGEConv((-1, -1), out_channels),\n",
    "            ('ip', 'rev_through', 'transaction'): SAGEConv((-1, -1), out_channels),\n",
    "            ('device', 'rev_via', 'transaction'): SAGEConv((-1, -1), out_channels),\n",
    "        })\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = self.conv1(x_dict, edge_index_dict)\n",
    "        x_dict = {key: x.relu() for key, x in x_dict.items()}\n",
    "        x_dict = self.conv2(x_dict, edge_index_dict)\n",
    "        return x_dict\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(hidden_channels, out_channels)\n",
    "        self.lin = Linear(out_channels, 1)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        return self.lin(z_dict['transaction']).view(-1)\n",
    "\n",
    "\n",
    "# Load the saved model\n",
    "model = GNN(hidden_channels=64, out_channels=32)\n",
    "model.load_state_dict(torch.load('fraud_detection_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Initialize encoders and scaler (these should be the same as used in training)\n",
    "encoder = LabelEncoder()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "def get_user_input():\n",
    "    print(\"Please enter the transaction details:\")\n",
    "    transaction = {\n",
    "        'TransactionID': input(\"Transaction ID: \"),\n",
    "        'ProductCD': input(\"Product Code: \"),\n",
    "        'TransactionAmt': float(input(\"Transaction Amount: \")),\n",
    "        'card_type': input(\"Card Type: \"),\n",
    "        'card_no': input(\"Card Number (last 4 digits): \"),\n",
    "        'email_domain': input(\"Email Domain: \"),\n",
    "        'IpAddress': input(\"IP Address: \"),\n",
    "        'DeviceID': input(\"Device ID: \")\n",
    "    }\n",
    "    return pd.DataFrame([transaction])\n",
    "\n",
    "def preprocess_input(transaction_df):\n",
    "    # Encode categorical variables (use the same encoding as in training)\n",
    "    categorical_cols = ['ProductCD', 'card_type', 'email_domain', 'DeviceID']\n",
    "    for col in categorical_cols:\n",
    "        transaction_df[col] = encoder.fit_transform(transaction_df[col].astype(str))\n",
    "\n",
    "    # Normalize TransactionAmt (use the same scaling as in training)\n",
    "    transaction_df['TransactionAmt'] = scaler.fit_transform(transaction_df[['TransactionAmt']])\n",
    "\n",
    "    return transaction_df\n",
    "\n",
    "def create_graph_data(transaction_df):\n",
    "    data = HeteroData()\n",
    "    \n",
    "    # Add node features\n",
    "    data['transaction'].x = torch.tensor(transaction_df[['ProductCD', 'TransactionAmt']].values, dtype=torch.float)\n",
    "    data['card'].x = torch.tensor(transaction_df['card_type'].values.reshape(-1, 1), dtype=torch.float)\n",
    "    data['email'].x = torch.tensor(transaction_df['email_domain'].values.reshape(-1, 1), dtype=torch.float)\n",
    "    data['ip'].x = torch.tensor(transaction_df['IpAddress'].astype('category').cat.codes.values.reshape(-1, 1), dtype=torch.float)\n",
    "    data['device'].x = torch.tensor(transaction_df['DeviceID'].values.reshape(-1, 1), dtype=torch.float)\n",
    "    \n",
    "    # Add edges (assuming single transaction, so all indices are 0)\n",
    "    data['transaction', 'uses', 'card'].edge_index = torch.tensor([[0], [0]], dtype=torch.long)\n",
    "    data['transaction', 'from', 'email'].edge_index = torch.tensor([[0], [0]], dtype=torch.long)\n",
    "    data['transaction', 'through', 'ip'].edge_index = torch.tensor([[0], [0]], dtype=torch.long)\n",
    "    data['transaction', 'via', 'device'].edge_index = torch.tensor([[0], [0]], dtype=torch.long)\n",
    "    data['card', 'rev_uses', 'transaction'].edge_index = torch.tensor([[0], [0]], dtype=torch.long)\n",
    "    data['email', 'rev_from', 'transaction'].edge_index = torch.tensor([[0], [0]], dtype=torch.long)\n",
    "    data['ip', 'rev_through', 'transaction'].edge_index = torch.tensor([[0], [0]], dtype=torch.long)\n",
    "    data['device', 'rev_via', 'transaction'].edge_index = torch.tensor([[0], [0]], dtype=torch.long)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def predict_fraud(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x_dict, data.edge_index_dict)\n",
    "        prob = torch.sigmoid(out)\n",
    "        return prob.item()\n",
    "\n",
    "# Main prediction flow\n",
    "if __name__ == \"__main__\":\n",
    "    # Get user input\n",
    "    transaction_df = get_user_input()\n",
    "    \n",
    "    # Preprocess the input\n",
    "    preprocessed_df = preprocess_input(transaction_df)\n",
    "    \n",
    "    # Create graph data\n",
    "    graph_data = create_graph_data(preprocessed_df)\n",
    "    \n",
    "    # Make prediction\n",
    "    fraud_probability = predict_fraud(model, graph_data)\n",
    "    \n",
    "    print(f\"Fraud probability for the transaction: {fraud_probability:.4f}\")\n",
    "    if fraud_probability > 0.5:\n",
    "        print(\"This transaction is likely to be fraudulent.\")\n",
    "    else:\n",
    "        print(\"This transaction appears to be legitimate.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN_env",
   "language": "python",
   "name": "gnn_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
